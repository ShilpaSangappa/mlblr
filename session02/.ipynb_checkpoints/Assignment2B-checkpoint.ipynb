{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: \n",
    "Read input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,0,1,0], [1,0,1,1], [0,1,0,1]])\n",
    "y = np.array([[1], [1], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: \n",
    "Initialize weights and biases with random values (There are methods to initialize weights and biases but for now initialize with random values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22060317 0.50605656 0.25878311]\n",
      " [0.31713256 0.86296086 0.40861328]\n",
      " [0.66894608 0.16998899 0.46500975]\n",
      " [0.6299352  0.38595048 0.88567273]]\n",
      "\n",
      "\n",
      "[[0.48224255 0.3645863  0.13582952]]\n",
      "\n",
      "\n",
      "[[0.49702365]\n",
      " [0.17177305]\n",
      " [0.84804526]]\n",
      "\n",
      "\n",
      "[[0.02443264]]\n"
     ]
    }
   ],
   "source": [
    "#Generate 4*3 random numbers for the weights for first hidden layer\n",
    "wh = np.random.rand(4,3)\n",
    "print(wh)\n",
    "print('\\n')\n",
    "\n",
    "#Generate 1*3 random numbers for the bias for the first hidden layer\n",
    "bh = np.random.rand(1,3)\n",
    "print(bh)\n",
    "print('\\n')\n",
    "\n",
    "#Generate 1*3 random numbers for the weights for output layer\n",
    "wout = np.random.rand(3,1)\n",
    "print(wout)\n",
    "print('\\n')\n",
    "\n",
    "#Generate 1*1 random numbers for the bias for output layer\n",
    "bout = np.random.rand(1,1)\n",
    "print(bout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "Calculate hidden layer input\n",
    "\n",
    "hidden_layer_input = matrix_dot_product(X,wh) + bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.37179179 1.04063185 0.85962238]\n",
      " [2.00172699 1.42658234 1.7452951 ]\n",
      " [1.42931031 1.61349765 1.43011552]]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_input = np.dot(X,wh) + bh\n",
    "print(hidden_layer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: \n",
    "Perform non-linear transformation on hidden linear input.\n",
    "\n",
    "hiddenlayer_activations = sigmoid(hidden_layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79766949 0.7389719  0.70258175]\n",
      " [0.88097828 0.80636825 0.85135839]\n",
      " [0.80679383 0.83389642 0.80691931]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "print(hiddenlayer_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: \n",
    "\n",
    "Perform linear and non-linear transformation of hidden layer activation at output layer\n",
    "\n",
    "##### Output layer Summation:\n",
    "output_layer_input = matrix_dot_product (hiddenlayer_activations * wout ) + bout \n",
    "\n",
    "##### Output layer Activation:\n",
    "output = sigmoid(output_layer_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75834912]\n",
      " [0.78964759]\n",
      " [0.77781413]]\n"
     ]
    }
   ],
   "source": [
    "output_layer_input = np.dot(hiddenlayer_activations,wout) + bout\n",
    "output = sigmoid(output_layer_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:\n",
    "Calculate gradient of Error(E) at output layer\n",
    "\n",
    "E = y-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24165088]\n",
      " [ 0.21035241]\n",
      " [-0.77781413]]\n"
     ]
    }
   ],
   "source": [
    "E = y-output\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: \n",
    "Compute slope at output and hidden layer\n",
    "\n",
    "Slope_output_layer= derivatives_sigmoid(output)\n",
    "\n",
    "Slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18325573]\n",
      " [0.16610428]\n",
      " [0.17281931]]\n",
      "[[0.16139287 0.19289243 0.20896063]\n",
      " [0.10485555 0.1561385  0.12654728]\n",
      " [0.15587755 0.13851318 0.15580053]]\n"
     ]
    }
   ],
   "source": [
    "def derivatives_sigmoid(x):\n",
    "    return x*(1-x)\n",
    "slope_output_layer= derivatives_sigmoid(output)\n",
    "print(slope_output_layer)\n",
    "\n",
    "slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "print(slope_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7:\n",
    "Compute delta at output layer\n",
    "\n",
    "d_output = E * slope_output_layer*lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04428391]\n",
      " [ 0.03494044]\n",
      " [-0.1344213 ]]\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "d_output = E * slope_output_layer*lr\n",
    "print(d_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: \n",
    "Calculate Error at hidden layer\n",
    "\n",
    "Error_at_hidden_layer = matrix_dot_product(d_output, wout.Transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02201015  0.00760678  0.03755476]\n",
      " [ 0.01736622  0.00600183  0.02963107]\n",
      " [-0.06681057 -0.02308996 -0.11399535]]\n"
     ]
    }
   ],
   "source": [
    "Error_at_hidden_layer = np.dot(d_output, wout.T)\n",
    "print(Error_at_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9:\n",
    "Compute delta at hidden layer\n",
    "\n",
    "d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00355228  0.00146729  0.00784747]\n",
      " [ 0.00182094  0.00093712  0.00374973]\n",
      " [-0.01041427 -0.00319826 -0.01776054]]\n"
     ]
    }
   ],
   "source": [
    "d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "print(d_hiddenlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: \n",
    "Update weight at both output and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45467906]\n",
      " [0.12057903]\n",
      " [0.80043802]]\n",
      "[[0.22597639 0.50846097 0.2703803 ]\n",
      " [0.3067183  0.8597626  0.39085274]\n",
      " [0.67431931 0.17239339 0.47660695]\n",
      " [0.62134188 0.38368934 0.87166192]]\n"
     ]
    }
   ],
   "source": [
    "wout = wout + np.dot(hiddenlayer_activations.T, d_output) * lr\n",
    "\n",
    "wh = wh+ np.dot(X.T,d_hiddenlayer) * lr\n",
    "\n",
    "print(wout)\n",
    "print(wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: \n",
    "Update biases at both output and hidden layer\n",
    "\n",
    "bh = bh + sum(d_hiddenlayer, axis=0) * learning_rate\n",
    "\n",
    "bout = bout + sum(d_output, axis=0)*learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47720151 0.36379245 0.12966618]]\n",
      "[[-0.03076431]]\n"
     ]
    }
   ],
   "source": [
    "bh = bh + np.sum(d_hiddenlayer, axis=0) * lr\n",
    "\n",
    "bout = bout + np.sum(d_output, axis=0)*lr\n",
    "\n",
    "print(bh)\n",
    "print(bout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
